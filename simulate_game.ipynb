{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79869774-a5ee-4798-9645-f23554603451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from env.res_env_all import ResistanceFinalEnv\n",
    "from env.naive_agents import NaiveEvilPolicy, RandomPolicy\n",
    "\n",
    "from runner.runner_all import RunnerMA_Both\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from runner.game import simulate_game\n",
    "from runner.config import Args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7555b42c-1f72-45b2-a23a-b8030313760c",
   "metadata": {},
   "source": [
    "### Restore trained policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b45546-68f2-45de-ae99-ef733e35092b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "env = ResistanceFinalEnv()\n",
    "config = {\n",
    "    'all_args': Args(),\n",
    "    'env': env,\n",
    "    'device': 'cpu',\n",
    "}\n",
    "runner = RunnerMA_Both(config)\n",
    "\n",
    "runner.restore('models', version='temp')\n",
    "\n",
    "\n",
    "\n",
    "evil_policy = runner.trainer_evil.policy\n",
    "\n",
    "good_policy = runner.trainer_good.policy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456b4b12-ede1-4569-9b93-eaa797358328",
   "metadata": {},
   "source": [
    "### Simulate a Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90ea7331-ffb4-4c51-9573-f6f3a0eb41d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Start of the Game --\n",
      "Good Team: ['player_1', 'player_4', 'player_5']\n",
      "Evil Team: ['player_2', 'player_3']\n",
      "===================\n",
      "Round: 0, Phase: 0, Vote attempt 1\n",
      "player_4 ðŸ˜‡: [0, 1, 0, 0, 1] (1.00)\n",
      "Rewards\n",
      "player_4 ðŸ˜‡: -0.0\n",
      "===================\n",
      "Round: 0, Phase: 1, Vote attempt 1\n",
      "player_1 ðŸ˜‡: 0 (1.00)\n",
      "player_2 ðŸ˜ˆ: 1 (None)\n",
      "player_3 ðŸ˜ˆ: 1 (None)\n",
      "player_4 ðŸ˜‡: 0 (1.00)\n",
      "player_5 ðŸ˜‡: 1 (1.00)\n",
      "Rewards\n",
      "player_1 ðŸ˜‡: 0.0\n",
      "player_2 ðŸ˜ˆ: 0\n",
      "player_3 ðŸ˜ˆ: 0\n",
      "player_4 ðŸ˜‡: 0.0\n",
      "player_5 ðŸ˜‡: -0.0\n",
      "===================\n",
      "Round: 0, Phase: 2, Vote attempt 1\n",
      "player_2 ðŸ˜ˆ: 1 (None)\n",
      "player_5 ðŸ˜‡: 0 (1.00)\n",
      " ---> Round 0: ðŸ˜‡ 0 : 1 ðŸ˜ˆ\n",
      "Rewards\n",
      "player_2 ðŸ˜ˆ: 0\n",
      "player_5 ðŸ˜‡: 0\n",
      "===================\n",
      "Round: 1, Phase: 0, Vote attempt 1\n",
      "player_5 ðŸ˜‡: [1, 0, 0, 1, 1] (0.99)\n",
      "Rewards\n",
      "player_5 ðŸ˜‡: 0.15\n",
      "===================\n",
      "Round: 1, Phase: 1, Vote attempt 1\n",
      "player_1 ðŸ˜‡: 0 (1.00)\n",
      "player_2 ðŸ˜ˆ: 0 (None)\n",
      "player_3 ðŸ˜ˆ: 0 (None)\n",
      "player_4 ðŸ˜‡: 0 (1.00)\n",
      "player_5 ðŸ˜‡: 0 (0.94)\n",
      "Rewards\n",
      "player_1 ðŸ˜‡: -0.15000000000000002\n",
      "player_2 ðŸ˜ˆ: 0\n",
      "player_3 ðŸ˜ˆ: 0\n",
      "player_4 ðŸ˜‡: -0.15000000000000002\n",
      "player_5 ðŸ˜‡: -0.15000000000000002\n",
      "===================\n",
      "Round: 1, Phase: 0, Vote attempt 2\n",
      "player_1 ðŸ˜‡: [1, 1, 0, 1, 0] (0.43)\n",
      "Rewards\n",
      "player_1 ðŸ˜‡: -0.15\n",
      "===================\n",
      "Round: 1, Phase: 1, Vote attempt 2\n",
      "player_1 ðŸ˜‡: 0 (1.00)\n",
      "player_2 ðŸ˜ˆ: 1 (None)\n",
      "player_3 ðŸ˜ˆ: 1 (None)\n",
      "player_4 ðŸ˜‡: 0 (1.00)\n",
      "player_5 ðŸ˜‡: 0 (0.96)\n",
      "Rewards\n",
      "player_1 ðŸ˜‡: 0.1\n",
      "player_2 ðŸ˜ˆ: 0\n",
      "player_3 ðŸ˜ˆ: 0\n",
      "player_4 ðŸ˜‡: 0.1\n",
      "player_5 ðŸ˜‡: 0.1\n",
      "===================\n",
      "Round: 1, Phase: 0, Vote attempt 3\n",
      "player_2 ðŸ˜ˆ: [0, 1, 1, 0, 1] (None)\n",
      "Rewards\n",
      "player_2 ðŸ˜ˆ: 0\n",
      "===================\n",
      "Round: 1, Phase: 1, Vote attempt 3\n",
      "player_1 ðŸ˜‡: 0 (1.00)\n",
      "player_2 ðŸ˜ˆ: 1 (None)\n",
      "player_3 ðŸ˜ˆ: 1 (None)\n",
      "player_4 ðŸ˜‡: 0 (1.00)\n",
      "player_5 ðŸ˜‡: 0 (0.65)\n",
      "Rewards\n",
      "player_1 ðŸ˜‡: 0.1\n",
      "player_2 ðŸ˜ˆ: 0\n",
      "player_3 ðŸ˜ˆ: 0\n",
      "player_4 ðŸ˜‡: 0.1\n",
      "player_5 ðŸ˜‡: 0.1\n",
      "===================\n",
      "Round: 1, Phase: 0, Vote attempt 4\n",
      "player_3 ðŸ˜ˆ: [0, 0, 1, 1, 1] (None)\n",
      "Rewards\n",
      "player_3 ðŸ˜ˆ: 0\n",
      "===================\n",
      "Round: 1, Phase: 1, Vote attempt 4\n",
      "player_1 ðŸ˜‡: 1 (0.99)\n",
      "player_2 ðŸ˜ˆ: 1 (None)\n",
      "player_3 ðŸ˜ˆ: 1 (None)\n",
      "player_4 ðŸ˜‡: 0 (0.93)\n",
      "player_5 ðŸ˜‡: 1 (1.00)\n",
      "Rewards\n",
      "player_1 ðŸ˜‡: -0.15000000000000002\n",
      "player_2 ðŸ˜ˆ: 0\n",
      "player_3 ðŸ˜ˆ: 0\n",
      "player_4 ðŸ˜‡: 0.1\n",
      "player_5 ðŸ˜‡: -0.15000000000000002\n",
      "===================\n",
      "Round: 1, Phase: 2, Vote attempt 1\n",
      "player_3 ðŸ˜ˆ: 1 (None)\n",
      "player_4 ðŸ˜‡: 0 (1.00)\n",
      "player_5 ðŸ˜‡: 0 (1.00)\n",
      " ---> Round 1: ðŸ˜‡ 0 : 2 ðŸ˜ˆ\n",
      "Rewards\n",
      "player_3 ðŸ˜ˆ: 0\n",
      "player_4 ðŸ˜‡: 0\n",
      "player_5 ðŸ˜‡: 0\n",
      "===================\n",
      "Round: 2, Phase: 0, Vote attempt 1\n",
      "player_4 ðŸ˜‡: [1, 0, 0, 1, 0] (0.99)\n",
      "Rewards\n",
      "player_4 ðŸ˜‡: 0.3\n",
      "===================\n",
      "Round: 2, Phase: 1, Vote attempt 1\n",
      "player_1 ðŸ˜‡: 0 (1.00)\n",
      "player_2 ðŸ˜ˆ: 0 (None)\n",
      "player_3 ðŸ˜ˆ: 0 (None)\n",
      "player_4 ðŸ˜‡: 0 (1.00)\n",
      "player_5 ðŸ˜‡: 0 (0.63)\n",
      "Rewards\n",
      "player_1 ðŸ˜‡: -0.30000000000000004\n",
      "player_2 ðŸ˜ˆ: 0\n",
      "player_3 ðŸ˜ˆ: 0\n",
      "player_4 ðŸ˜‡: -0.30000000000000004\n",
      "player_5 ðŸ˜‡: -0.30000000000000004\n",
      "===================\n",
      "Round: 2, Phase: 0, Vote attempt 2\n",
      "player_5 ðŸ˜‡: [1, 0, 0, 1, 0] (0.97)\n",
      "Rewards\n",
      "player_5 ðŸ˜‡: 0.3\n",
      "===================\n",
      "Round: 2, Phase: 1, Vote attempt 2\n",
      "player_1 ðŸ˜‡: 0 (1.00)\n",
      "player_2 ðŸ˜ˆ: 0 (None)\n",
      "player_3 ðŸ˜ˆ: 0 (None)\n",
      "player_4 ðŸ˜‡: 0 (1.00)\n",
      "player_5 ðŸ˜‡: 0 (0.87)\n",
      "Rewards\n",
      "player_1 ðŸ˜‡: -0.30000000000000004\n",
      "player_2 ðŸ˜ˆ: 0\n",
      "player_3 ðŸ˜ˆ: 0\n",
      "player_4 ðŸ˜‡: -0.30000000000000004\n",
      "player_5 ðŸ˜‡: -0.30000000000000004\n",
      "===================\n",
      "Round: 2, Phase: 0, Vote attempt 3\n",
      "player_1 ðŸ˜‡: [1, 0, 0, 1, 0] (0.72)\n",
      "Rewards\n",
      "player_1 ðŸ˜‡: 0.3\n",
      "===================\n",
      "Round: 2, Phase: 1, Vote attempt 3\n",
      "player_1 ðŸ˜‡: 0 (1.00)\n",
      "player_2 ðŸ˜ˆ: 0 (None)\n",
      "player_3 ðŸ˜ˆ: 0 (None)\n",
      "player_4 ðŸ˜‡: 0 (1.00)\n",
      "player_5 ðŸ˜‡: 1 (0.73)\n",
      "Rewards\n",
      "player_1 ðŸ˜‡: -0.30000000000000004\n",
      "player_2 ðŸ˜ˆ: 0\n",
      "player_3 ðŸ˜ˆ: 0\n",
      "player_4 ðŸ˜‡: -0.30000000000000004\n",
      "player_5 ðŸ˜‡: 0.2\n",
      "===================\n",
      "Round: 2, Phase: 0, Vote attempt 4\n",
      "player_2 ðŸ˜ˆ: [1, 1, 0, 0, 0] (None)\n",
      "Rewards\n",
      "player_2 ðŸ˜ˆ: 0\n",
      "===================\n",
      "Round: 2, Phase: 1, Vote attempt 4\n",
      "player_1 ðŸ˜‡: 0 (0.93)\n",
      "player_2 ðŸ˜ˆ: 1 (None)\n",
      "player_3 ðŸ˜ˆ: 1 (None)\n",
      "player_4 ðŸ˜‡: 0 (1.00)\n",
      "player_5 ðŸ˜‡: 1 (0.98)\n",
      "Rewards\n",
      "player_1 ðŸ˜‡: 0.2\n",
      "player_2 ðŸ˜ˆ: 0\n",
      "player_3 ðŸ˜ˆ: 0\n",
      "player_4 ðŸ˜‡: 0.2\n",
      "player_5 ðŸ˜‡: -0.30000000000000004\n",
      "===================\n",
      "Round: 2, Phase: 2, Vote attempt 1\n",
      "player_1 ðŸ˜‡: 0 (1.00)\n",
      "player_2 ðŸ˜ˆ: 1 (None)\n",
      " ---> Round 2: ðŸ˜‡ 0 : 3 ðŸ˜ˆ\n",
      "Rewards\n",
      "player_1 ðŸ˜‡: -1\n",
      "player_2 ðŸ˜ˆ: 1\n",
      "The game ended in 21 turns.\n",
      "Final Rewards: \n",
      "player_1 ðŸ˜‡: -1\n",
      "player_2 ðŸ˜ˆ: 1\n",
      "player_3 ðŸ˜ˆ: 1\n",
      "player_4 ðŸ˜‡: -1\n",
      "player_5 ðŸ˜‡: -1\n",
      "Number of successful Quests: 0\n",
      "ðŸ˜ˆ Evil Team won ðŸ˜ˆ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'number of turns': 21, 'good victory': 0, 'number of rounds': 3}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "            0: good_policy,\n",
    "            1: NaiveEvilPolicy()\n",
    "        }\n",
    "env = ResistanceFinalEnv()\n",
    "simulate_game(env, config, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab9de8a-a0d4-4076-8ec5-43cdb2291d50",
   "metadata": {},
   "source": [
    "### Simulate n games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de93aad-5607-468c-882b-fa45437f4e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b9b2db6-8915-4d57-adc0-fe182e7752f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Victories Rate 0.182\n",
      "Av number of turns 26.64\n",
      "Av number of succ Quests 0.821\n"
     ]
    }
   ],
   "source": [
    "n_games = 1000\n",
    "good_victories = 0\n",
    "number_of_turns = 0\n",
    "number_of_success = 0\n",
    "for i in range(n_games):\n",
    "    stat = simulate_game(env, config)\n",
    "    good_victories += stat['good victory']\n",
    "    number_of_turns  += stat['number of turns']\n",
    "    if stat['good victory'] == 1:\n",
    "        number_of_success += 3\n",
    "    else:\n",
    "        number_of_success += (stat['number of rounds'] - 3)\n",
    "    \n",
    "print('Good Victories Rate', good_victories / n_games)\n",
    "print('Av number of turns', number_of_turns/ n_games)\n",
    "print('Av number of succ Quests', number_of_success/ n_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb096273-5868-48a9-ae57-b1c875597636",
   "metadata": {
    "tags": []
   },
   "source": [
    "config = {\n",
    "            0: good_policy,\n",
    "            1: NaiveEvilPolicy()\n",
    "        }\n",
    "simulate_game(env, config, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d2836d-b7d2-4245-9a71-e7a801766d7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "n_games = 100\n",
    "good_victories = 0\n",
    "number_of_turns = 0\n",
    "for i in range(n_games):\n",
    "    stat = simulate_game(env, config)\n",
    "    good_victories += stat['good victory']\n",
    "    number_of_turns  += stat['number of turns']\n",
    "print('Good Victories Rate', good_victories / n_games)\n",
    "print('Av number of turns', number_of_turns/ n_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6212b48-33d5-44fa-a5e3-459d8d1ae9c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "config = {\n",
    "            0: good_policy,\n",
    "            1: RandomPolicy()\n",
    "        }\n",
    "env = ResistanceFinalEnv()\n",
    "n_games = 1000\n",
    "good_victories = 0\n",
    "number_of_turns = 0\n",
    "number_of_success = 0\n",
    "for i in range(n_games):\n",
    "    stat = simulate_game(env, config)\n",
    "    good_victories += stat['good victory']\n",
    "    number_of_turns  += stat['number of turns']\n",
    "    if stat['good victory'] == 1:\n",
    "        number_of_success += 3\n",
    "    else:\n",
    "        number_of_success += (stat['number of rounds'] - 3)\n",
    "\n",
    "print('Good vs Random: ')\n",
    "print('Good Victories Rate', good_victories / n_games)\n",
    "print('Av number of turns', number_of_turns/ n_games)\n",
    "print('Av number of succ Quests', number_of_success/ n_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105fa56-d9fa-4755-afe4-96634368ef0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "config = {\n",
    "            0: RandomPolicy(),\n",
    "            1: evil_policy\n",
    "        }\n",
    "env = ResistanceFinalEnv()\n",
    "n_games = 1000\n",
    "good_victories = 0\n",
    "number_of_turns = 0\n",
    "number_of_success = 0\n",
    "for i in range(n_games):\n",
    "    stat = simulate_game(env, config)\n",
    "    good_victories += stat['good victory']\n",
    "    number_of_turns  += stat['number of turns']\n",
    "    if stat['good victory'] == 1:\n",
    "        number_of_success += 3\n",
    "    else:\n",
    "        number_of_success += (stat['number of rounds'] - 3)\n",
    "\n",
    "print('Evil vs Random: ')\n",
    "print('Good Victories Rate', good_victories / n_games)\n",
    "print('Av number of turns', number_of_turns/ n_games)\n",
    "print('Av number of succ Quests', number_of_success/ n_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee015b5-e7a5-496d-8116-5458d8617e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae00a41-7991-45ca-a0ae-2aadf4d16c93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['player_3', 'player_5']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.evil_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "994c3c12-4fd3-4f7c-9739-62d6aadb8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.quest_team = [0, 1, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "604abdb1-1e6f-4fb3-a206-5e974ff64e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['player_1', 'player_3']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.evil_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bd0a2d3-c682-46d1-9064-b325751182bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_evil_in_quest_team():\n",
    "    for evil_player in env.evil_players:\n",
    "        evil_player_idx = int(evil_player[-1]) - 1\n",
    "        if env.quest_team[evil_player_idx] == 1:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9afc749b-46d6-417b-842f-6f83c377c9b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_is_evil_in_quest_team() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a011762-3e8a-499c-9c9b-4269b5df0333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "def init(module, weight_init, bias_init, gain=1):\n",
    "    weight_init(module.weight.data, gain=gain)\n",
    "    if module.bias is not None:\n",
    "        bias_init(module.bias.data)\n",
    "    return module\n",
    "\n",
    "class MLPLayer(nn.Module):\n",
    "    def __init__(self, input_dim, layer_sizes: list, use_orthogonal, use_ReLU):\n",
    "        super(MLPLayer, self).__init__()\n",
    "        active_func = [nn.Tanh(), nn.ReLU()][use_ReLU]\n",
    "        init_method = [nn.init.xavier_uniform_, nn.init.orthogonal_][use_orthogonal]\n",
    "        gain = nn.init.calculate_gain(['tanh', 'relu'][use_ReLU])\n",
    "\n",
    "        def init_(m):\n",
    "            return init(m, init_method, lambda x: nn.init.constant_(x, 0), gain=gain)\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        prev_size = input_dim\n",
    "        for size in layer_sizes:\n",
    "            fc = nn.Linear(prev_size, size)\n",
    "            init_(fc)\n",
    "            self.layers.append(\n",
    "                nn.Sequential(fc, active_func, nn.LayerNorm(size))\n",
    "            )\n",
    "            prev_size = size\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MLPBase(nn.Module):\n",
    "    def __init__(self, args, obs_dim):\n",
    "        super(MLPBase, self).__init__()\n",
    "        self._use_feature_normalization = args.use_feature_normalization  # True\n",
    "        self._use_orthogonal = args.use_orthogonal  # True\n",
    "        self._use_ReLU = args.use_ReLU  # True\n",
    "        self.hidden_sizes_list = args.hidden_sizes_list\n",
    "\n",
    "        if self._use_feature_normalization:\n",
    "            self.feature_norm = nn.LayerNorm(obs_dim)\n",
    "\n",
    "        self.mlp = MLPLayer(obs_dim, self.hidden_sizes_list,\n",
    "                            self._use_orthogonal, self._use_ReLU)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self._use_feature_normalization:\n",
    "            x = self.feature_norm(x)\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8296473f-d1c3-46c9-9b46-70acc033b66b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPBase(\n",
      "  (feature_norm): LayerNorm((420,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): MLPLayer(\n",
      "    (layers): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=420, out_features=256, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.use_feature_normalization = True\n",
    "        self.use_orthogonal = True\n",
    "        self.use_ReLU = True\n",
    "        self.hidden_sizes_list = [256, 128, 64]\n",
    "\n",
    "args = Args()\n",
    "obs_dim = 420\n",
    "\n",
    "model = MLPBase(args, obs_dim)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a6432eb-64a8-44c0-841a-d44ffd52eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_first_5_elements_with_multiple_ones(lst):\n",
    "    # Loop through the list in reverse order in chunks of 5 elements\n",
    "    for i in range(len(lst) - 1, 3, -5):\n",
    "        # Get the current chunk of 5 elements\n",
    "        chunk = lst[i-4:i+1]\n",
    "        \n",
    "        # Check if there is more than one `1` in the current chunk\n",
    "        if chunk.count(1) > 1:\n",
    "            return chunk\n",
    "    \n",
    "    # If no chunk with more than one `1` is found, return an empty list\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2866d619-9f0e-4e73-8558-1e1ce7bc1094",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_find_first_5_elements_with_multiple_ones([1,0,0,0,0,  1,0,0,1,1, 0,0,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d6e4786-8a6f-46dd-9b3f-1c9d0e578b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "chosen_action  = random.choice(range(1, 11))\n",
    "chosen_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb4b0e01-9334-4169-8f2e-4b999b414cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'simpledoorkey': {'episode': 100,\n",
       "  'level': 'easy',\n",
       "  'description': \"an agent in a minigrid environment in reinfrocement learning, the task of the agent is toggle the door in the maze with key. please help agent to plan the next action given agent's current observations and statu: carry {object} or none. Availabel actions may includes: explore, go to {object}, pick up {object}, toggle {object}. the actions should be displayed in a list. Do not explain the reasoning. \\n \",\n",
       "  'example': 'observation: {observed nothing}, action: {explore}. \\n observation: {observed a door}, action: {explore}. \\n observation: {observed a key, observed a door}, action: {go to the key, pick up the key, go to the door, toggle the door}. \\n observation: {observed a door, carry key}, action: {go to the door, toggle the door}. \\n observation: {observed a key}, action: {go to the key, pick up the key, explore}.',\n",
       "  'configurations': 'MiniGrid-SimpleDoorKey-Min5-Max10-View3'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"simpledoorkey\":{\n",
    "        \"episode\": 100,\n",
    "        \"level\": \"easy\",\n",
    "        \"description\": \"an agent in a minigrid environment in reinfrocement learning, the task of the agent is toggle the door in the maze with key. please help agent to plan the next action given agent's current observations and statu: carry {object} or none. Availabel actions may includes: explore, go to {object}, pick up {object}, toggle {object}. the actions should be displayed in a list. Do not explain the reasoning. \\n \",\n",
    "        \"example\": \"observation: {observed nothing}, action: {explore}. \\n observation: {observed a door}, action: {explore}. \\n observation: {observed a key, observed a door}, action: {go to the key, pick up the key, go to the door, toggle the door}. \\n observation: {observed a door, carry key}, action: {go to the door, toggle the door}. \\n observation: {observed a key}, action: {go to the key, pick up the key, explore}.\",\n",
    "        \"configurations\": \"MiniGrid-SimpleDoorKey-Min5-Max10-View3\" \n",
    "    },\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea74ecd4-a6d3-4fc7-9851-1a492ab57c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import requests, os\n",
    "\n",
    "class Base_Planner(ABC):\n",
    "    \"\"\"The base class for Planner.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dialogue_system = ''                  \n",
    "        self.dialogue_user = ''\n",
    "        self.dialogue_logger = ''         \n",
    "        self.show_dialogue = False\n",
    "        self.llm_model = None\n",
    "        self.llm_url = None\n",
    "        \n",
    "    def reset(self, show=False):\n",
    "        self.dialogue_user = ''\n",
    "        self.dialogue_logger = ''\n",
    "        self.show_dialogue = show\n",
    "        \n",
    "    ## initial prompt, write in 'prompt/task_info.json\n",
    "    def initial_planning(self, decription, example):\n",
    "        if self.llm_model is None:\n",
    "            assert \"no select Large Language Model\"\n",
    "        prompts = decription + example\n",
    "        self.dialogue_system += decription + \"\\n\"\n",
    "        self.dialogue_system += example + \"\\n\"\n",
    "\n",
    "        ## set system part\n",
    "        server_error_cnt = 0\n",
    "        while server_error_cnt<10:\n",
    "            try:\n",
    "                url = self.llm_url\n",
    "                headers = {'Content-Type': 'application/json'}\n",
    "                \n",
    "                data = {'model': self.llm_model, \"messages\":[{\"role\": \"system\", \"content\": prompts}]}\n",
    "                response = requests.post(url, headers=headers, json=data)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    result = response.json()                    \n",
    "                    server_flag = 1\n",
    "                                \n",
    "                if server_flag:\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                server_error_cnt += 1\n",
    "                print(e)   \n",
    "        \n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7a2564a-48ef-416c-b9fc-030f324b33d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Base_Planner()\n",
    "c.show_dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfb344c6-8061-44c2-bcf8-a94a045b33c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "description = ''\n",
    "example = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281fe74c-145e-4322-93b7-1f32572d27a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c81373d-413a-4dfe-9c9f-fc7e7caffadc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
      "Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
      "Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
      "Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
      "Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
      "Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
      "Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
      "Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
      "Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
      "Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n"
     ]
    }
   ],
   "source": [
    "c.initial_planning(description, example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ea8fd-e978-46ed-8642-59f7aa3f8ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24038bb3-6162-424b-9594-695ba08e8614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
